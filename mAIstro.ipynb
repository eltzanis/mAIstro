{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import yaml\n",
    "import json\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import tempfile\n",
    "import subprocess\n",
    "from typing import Dict, Optional, List, Tuple\n",
    "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.api.types import is_numeric_dtype, is_datetime64_any_dtype, is_categorical_dtype\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "import SimpleITK as sitk\n",
    "from radiomics import featureextractor\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, f_regression, mutual_info_classif, mutual_info_regression, RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, roc_auc_score, roc_curve, auc,\n",
    "    classification_report, mean_squared_error, mean_absolute_error,\n",
    "    r2_score, explained_variance_score, mean_absolute_percentage_error\n",
    ")\n",
    "from mAIstro_tools import (\n",
    "    PyRadiomicsFeatureExtractionTool,\n",
    "    EDAToolException,\n",
    "    ExploratoryDataAnalysisTool,\n",
    "    FeatureImportanceAnalysisTool,\n",
    "    NNUNetTrainingTool,\n",
    "    NNUNetInferenceTool,\n",
    "    TotalSegmentatorTool,\n",
    "    PyCaretClassificationTool,\n",
    "    PyCaretInferenceTool,\n",
    "    PyCaretRegressionInferenceTool,\n",
    "    PyCaretRegressionTool,\n",
    "    MedicalImageDataset,\n",
    "    PyTorchResNetTrainingTool,\n",
    "    PyTorchResNetInferenceTool,\n",
    "    PyTorchVGG16InferenceTool,\n",
    "    PyTorchVGG16TrainingTool,\n",
    "    PyTorchInceptionV3InferenceTool,\n",
    "    PyTorchInceptionV3TrainingTool\n",
    ")\n",
    "from smolagents import Tool, CodeAgent, LiteLLMModel, GradioUI, HfApiModel\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyradiomics_feature_extraction_tool = PyRadiomicsFeatureExtractionTool()\n",
    "eda_tool = ExploratoryDataAnalysisTool()\n",
    "feature_selection_tool = FeatureImportanceAnalysisTool()\n",
    "nnunet_training_tool = NNUNetTrainingTool()\n",
    "nnunet_inference_tool = NNUNetInferenceTool()\n",
    "totalsegmentator_tool = TotalSegmentatorTool()\n",
    "pycaret_class_inference_tool = PyCaretInferenceTool()\n",
    "pycaret_class_training_tool = PyCaretClassificationTool()\n",
    "pycaret_regression_training_tool = PyCaretRegressionTool()\n",
    "pycaret_regression_inference_tool = PyCaretRegressionInferenceTool()\n",
    "pytorch_resnet_inference_tool = PyTorchResNetInferenceTool()\n",
    "pytorch_resnet_training_tool = PyTorchResNetTrainingTool()\n",
    "pytorch_vgg16_inference_tool = PyTorchVGG16InferenceTool()\n",
    "pytorch_vgg16_training_tool = PyTorchVGG16TrainingTool()\n",
    "pytorch_inceptionv3_inference_tool = PyTorchInceptionV3InferenceTool()\n",
    "pytorch_inceptionv3_training_tool = PyTorchInceptionV3TrainingTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use models through API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt-4.1\n",
    "model = LiteLLMModel(model_id=\"openai/gpt-4.1\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#gpt-4o\n",
    "#model = LiteLLMModel(model_id=\"openai/gpt-4o\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#claude\n",
    "#model = LiteLLMModel(model_id=\"anthropic/claude-3-7-sonnet-20250219\", api_key=\"YOUR_API_KEY_HERE\") \n",
    "#deepseek V3\n",
    "#model = LiteLLMModel(model_id=\"deepseek/deepseek-chat\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#deepseek R1\n",
    "#model = LiteLLMModel(model_id=\"deepseek/deepseek-reasoner\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "#hf API\n",
    "#Qwen\n",
    "#model_id = \"Qwen/QwQ-32B\" \n",
    "#model = HfApiModel(model_id=model_id, token=\"YOUR_API_KEY_HERE\")\n",
    "#Llama 3.3\n",
    "#model_id = \"meta-llama/Llama-3.3-70B-Instruct\" \n",
    "#model = HfApiModel(model_id=model_id, token=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "#Together AI API\n",
    "#llama-4-Scout\n",
    "#model = LiteLLMModel(model_id=\"together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#QwQ-32B\n",
    "#model = LiteLLMModel(model_id=\"together_ai/Qwen/QwQ-32B\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#Llama 3.3\n",
    "#model = LiteLLMModel(model_id=\"together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#Llama 3.1 8b\n",
    "#model = LiteLLMModel(model_id=\"together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-classifier\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#Mistral 24b\n",
    "#model = LiteLLMModel(model_id=\"together_ai/mistralai/Mistral-Small-24B-Instruct-2501\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#Mistral 7b\n",
    "#model = LiteLLMModel(model_id=\"together_ai/mistralai/Mistral-7B-Instruct-v0.2\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#DeepSeek R1 Distill Qwen 14B\n",
    "#model = LiteLLMModel(model_id=\"together_ai/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\", api_key=\"YOUR_API_KEY_HERE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Radiomic extraction Agent\n",
    "radiomic_extraction_agent = CodeAgent(\n",
    "    tools = [pyradiomics_feature_extraction_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['os', 'pandas'],\n",
    "    name=\"radiomic_extraction_agent\",\n",
    "    description=\"Extracts radiomic features from medical images and saves them as CSV files\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#EDA Agent\n",
    "eda_agent = CodeAgent(\n",
    "    tools = [eda_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['os', 'pandas'],\n",
    "    name=\"eda_agent\",\n",
    "    description=\"Performs comprehensive exploratory data analysis\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#Feature Importance Agent\n",
    "feature_selection_agent = CodeAgent(\n",
    "    tools = [feature_selection_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['os', 'pandas'],\n",
    "    name=\"feature_importance_agent\",\n",
    "    description=\"Performs feature importance analysis and exports the most important features to CSV files\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#nnUNet Agent\n",
    "nnunet_agent = agent = CodeAgent(\n",
    "    tools = [nnunet_training_tool, nnunet_inference_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['re', 'subprocess', 'os'],\n",
    "    name=\"nnunet_agent\",\n",
    "    description=\"Uses the nnUNet framework for training and inference of medical image segmentation models\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#TotalSegmentator Agent\n",
    "totalsegmentator_agent = CodeAgent(\n",
    "    tools = [totalsegmentator_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['os'],\n",
    "    name=\"totalsegmentator_agent\",\n",
    "    description=\"Utilizes the TotalSegmentator framework to segment organs and tissues in medical imaging data\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#PyCaret classification Agent (tabulated data)\n",
    "pycaret_classification_agent = CodeAgent(\n",
    "    tools = [pycaret_class_training_tool, pycaret_class_inference_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['pycaret', 'setup', 'compare_models', 'tune_model', 'blend_models', \n",
    "                    'pull', 'predict_model', 'save_model',\n",
    "                    'plot_model', 'interpret_model', 'cuml', 'pandas'],\n",
    "    name=\"pycaret_classification_agent\",\n",
    "    description=\"Builds and deploys classification models using the PyCaret framework on tabular data inputs\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#PyCaret regression Agent (tabulated data)\n",
    "pycaret_regression_agent = CodeAgent(\n",
    "    tools = [pycaret_regression_training_tool, pycaret_regression_inference_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['pycaret', 'setup', 'compare_models', 'tune_model', 'blend_models', \n",
    "                    'pull', 'predict_model', 'save_model',\n",
    "                    'plot_model', 'interpret_model', 'cuml', 'pandas'],\n",
    "    name=\"pycaret_regression_agent\",\n",
    "    description=\"Builds and deploys regression models using the PyCaret framework on tabular data inputs\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#Image classification Agent\n",
    "image_classification_agent = CodeAgent(\n",
    "    tools = [pytorch_resnet_training_tool, pytorch_resnet_inference_tool, \n",
    "             pytorch_inceptionv3_training_tool, pytorch_inceptionv3_inference_tool,\n",
    "             pytorch_vgg16_training_tool, pytorch_vgg16_inference_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['os'],\n",
    "    name=\"image_classification_agent\",\n",
    "    description=\"Builds and deploys ResNet, Inceptionv3 and VGG16 image classification models\",\n",
    "    max_steps = 5\n",
    ")\n",
    "\n",
    "#Master Agent\n",
    "master_agent = CodeAgent(\n",
    "    tools = [],\n",
    "    managed_agents=[radiomic_extraction_agent, eda_agent, feature_selection_agent,\n",
    "                    nnunet_agent, totalsegmentator_agent, pycaret_classification_agent,\n",
    "                    pycaret_regression_agent, image_classification_agent],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['os'],\n",
    "    name=\"master_agent\",\n",
    "    max_steps = 15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_agent.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radiomic Feature Extraction from CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test: Generic query\n",
    "rfe_ct_prompt_1 = \"\"\"\n",
    "Perform a comprehensive radiomic feature extraction for the CT scans in: \"/path/to/ct/images\".\n",
    "The corresponding masks are here: \"/path/to/ct/labels\".\n",
    "Save the results here: \"/path/to/output_directory\".\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(rfe_ct_prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test: Ask for specific radiomic freatures and filters.\n",
    "rfe_ct_prompt_2 = \"\"\"\n",
    "Extract shape and first order radiomic features for the CT scans in: \"/path/to/ct/images\".\n",
    "The respective masks are here: \"/path/to/ct/labels\".\n",
    "Save the results here: \"/path/to/output_directory\". \n",
    "Use the followng filters: Exponential, Gradient, LBP2D.\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(rfe_ct_prompt_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radiomic Feature Extraction from MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test: Generic query for pre contrast MRI images (MAMAMIA dataset)\n",
    "rfe_mri_prompt_1 = \"\"\"\n",
    "Perform a comprehensive radiomic feature extraction for the MR scans in: \"/path/to/mri/mama_mia/images_pre_contrast\".\n",
    "The respective masks are here: \"/path/to//mri/mama_mia/labels\". \n",
    "Save the results here: \"/path/to/output_directory\".\n",
    "\"\"\"\n",
    "master_agent.run(rfe_mri_prompt_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test: Extraction of radiomic features from mpMRI images (BraTS21 dataset) with multiple labels.\n",
    "#Asking specific features and filters\n",
    "\n",
    "rfe_mri_prompt_2 = \"\"\"\n",
    "Extract shape and glrlm and ngtdm radiomic features for the MR scans in: \"/path/to/mri/brats21/images\".\n",
    "The corresponding masks are here: \"/path/to/mri/brats21/labels\". \n",
    "Use the followng filters: Exponential, Gradient, SquareRoot.\n",
    "Save the results here: \"/path/to/output_directory\".\n",
    "\"\"\"\n",
    "master_agent.run(rfe_mri_prompt_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for breast wisconsin dataset\n",
    "eda_prompt_1 = \"\"\"\n",
    "Perform comprehensive exploratory data analysis for the file: \"/path/to/breast_cancer_wisconsin_diagnosis_datasetdata.csv\". \n",
    "Save the output here: \"/path/to/output_directory\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for predict_diabetes dataset\n",
    "eda_prompt_2 =\"\"\"\n",
    "Perform comprehensive EDA for the file: /path/to/predict_diabetes.csv\n",
    "Save the output here: \"/path/to/output_directory\"\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for heart disease dataset\n",
    "eda_prompt_3 = \"\"\"\n",
    "Perform comprehensive EDA for the file: /path/to/heart_disease_classification.csv. \n",
    "Save the results here: \"/path/to/output_directory\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for heart failure dataset\n",
    "eda_prompt_4 = \"\"\"\n",
    "Perform EDA for the file: /path/to/heart_failure_clinical_records_dataset.csv \n",
    "Save the results here: \"/path/to/output_directory\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for life expectancy dataset\n",
    "eda_prompt_5 = \"\"\"\n",
    "Perform comprehensive EDA for the file: /path/to/Life-Expectancy-Data.csv \n",
    "Save the results here: \"/path/to/output_directory\".\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(eda_prompt_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance Analysis and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for breast wisconsin dataset\n",
    "fia_prompt_1 = \"\"\"\n",
    "Perform feature importance analysis for the file: \"/path/to/breast_cancer_wisconsin_diagnosis_datasetdata.csv\".\n",
    "Save three csv files with the top 5, 10 and 20 features here: \"/path/to/output_directory\".\n",
    "Targert column is \"diagnosis\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for predict_diabetes dataset !Asking to export more features than the original file has.\n",
    "fia_prompt_2 = \"\"\"\n",
    "        Perform feature importance analysis for the file: \"/path/to/predict_diabetes.csv\".\n",
    "        Save three csv files with the top 5, 10 and 20 features here: \"/path/to/output_directory\".\n",
    "        Targert column is \"Outcome\".\n",
    "        \"\"\"\n",
    "\n",
    "#Prompt for heart disease dataset\n",
    "fia_prompt_3 = \"\"\"\n",
    "        Perform feature importance analysis for the file: \"/path/to/heart_disease_classification.csv\".\n",
    "        Save three csv files with the top 5, 10 features here: \"/path/to/output_directory\".\n",
    "        Targert column is \"target\".\n",
    "        \"\"\"\n",
    "\n",
    "#Prompt for heart failure dataset\n",
    "fia_prompt_4 = \"\"\"\n",
    "        Perform feature importance analysis for the file: \"/path/to/heart_failure_clinical_records_dataset.csv\".\n",
    "        Save three csv files with the top 8 features here: \"/path/to/output_directory\".\n",
    "        Targert column is \"DEATH_EVENT\".\n",
    "        \"\"\"\n",
    "\n",
    "#Prompt for life expectancy dataset\n",
    "fia_prompt_5 = \"\"\"\n",
    "        Perform feature importance analysis for the file: /path/to/Life-Expectancy-Data-Updated.csv\n",
    "        Save two csv files with the top 10 and 15 features here: \"/path/to/output_directory\"\n",
    "        Targert column is \"Life_expectancy\". Create plots.\n",
    "        \"\"\"\n",
    "\n",
    "master_agent.run(fia_prompt_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nnUNet framework - Train and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for training segmentation UNet (Brats21 dataset)\n",
    "nnunet_prompt_1 = 'Train a segmentation 3d full res for the dataset in: /nnUNet_raw/Dataset135_Brats21. For fold all'\n",
    "\n",
    "#Prompt for training segmentation UNet (Kits23 dataset)\n",
    "nnunet_prompt_1 = 'Train a segmentation 3d full res for the dataset in: /nnUNet_raw/Dataset140_Kits23. For fold all'\n",
    "\n",
    "#Prompt for inference mpMRI (Brats21 dataset)\n",
    "nnunet_prompt_2 =\"\"\"\n",
    "Using the nnUNet dataset 135, 3d full res fold_all model, segment the scans in: /inference_nnunet/brats21_validation. \n",
    "Output folder: /path/to/ouput_directory\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for inference mpMRI (Kits23 dataset)\n",
    "nnunet_prompt_2 =\"\"\"\n",
    "Using the nnUNet dataset 140, 3d full res fold_all model, segment the scans in: /inference_nnunet/kits23_validation. \n",
    "Output folder: /path/to/ouput_directory\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(nnunet_prompt_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TotalSegmentator Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt 1 segmenting only one organ (CT)\n",
    "totalsegmentator_prompt_1 = \"\"\"\n",
    "Use TotalSegmentator with the total task to segment only the spleen in the CT scan located at /path/to/ct_input \n",
    "Save the mask in this directory: /path/to/ouput_directory\n",
    "\"\"\"\n",
    "\n",
    "#Prompt 2 segmenting three organs (CT)\n",
    "totalsegmentator_prompt_2 = \"\"\"\n",
    "Use TotalSegmentator with the total task to segment only the liver, stomach and kidneys in the CT scan found at /path/to/ct_input  \n",
    "Save the mask here /path/to/ouput_directory\n",
    "\"\"\"\n",
    "\n",
    "#Prompt 3 segmenting all available organs (CT)\n",
    "totalsegmentator_prompt_3 = \"\"\"\n",
    "Use TotalSegmentator with the total task to segment all available organs in the CT scan located at \"/path/to/ct_input\".  \n",
    "Save the mask in this folder: /path/to/ouput_directory\n",
    "\"\"\"\n",
    "\n",
    "#Prompt 4 segmenting all available organs (MR)\n",
    "totalsegmentator_prompt_4 = \"\"\"\n",
    "Use TotalSegmentator with the total_mr task to segment all available organs in the MRI scan found at \"/path/to/ct_input\"\n",
    "Save the mask in this folder: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(totalsegmentator_prompt_4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training prompts Classification Model (Tabulated data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for classification model development Breast wisconsin\n",
    "tct_prompt_1 = \"\"\"\n",
    "Train a classification model using the tabulated data: /path/to/breast_cancer_wisconsin_diagnosis_datasetdata.csv.\n",
    "Target column: \"diagnosis\". Exclude lightgbm classifier. Set normalization and transormation to False.\n",
    "Save the results here: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification model development Predict diabetes\n",
    "tct_prompt_2 = \"\"\"\n",
    "Train a classification model using the file: /path/to/predict_diabetes.csv. \n",
    "Target column: \"Outcome\". Exclude lightgbm classifier.\n",
    "Save the results here: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification model development Predict Heart Disease\n",
    "tct_prompt_3 = \"\"\"\n",
    "Train a classification model using the file: /path/to/heart_disease_classification.csv\n",
    "Target column: \"target\". Exclude lightgbm classifier.\n",
    "Save the results here: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification model development Predict Heart Failure\n",
    "tct_prompt_4 = \"\"\"\n",
    "Train a classification model using the file: /path/to/heart_failure_clinical_records_dataset.csv\n",
    "Target column: \"DEATH_EVENT\". Exclude lightgbm, dummy and catboost classifier.\n",
    "Save the results here: \"/path/to/ouput_directory\"\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(tct_prompt_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference prompts Classification Model (Tabulated data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for classification inference Breast wisconsin tuned model 1\n",
    "ict_prompt_1 = \"\"\"\n",
    "Use the classification model: /path/to/breast_cancer_wisconsin/models/tuned_model_1/tuned_model_1.pkl \n",
    "Make predictions using the predictors in the file: /path/to/inferer_results/independent_eval_cohort.csv \n",
    "The ground truth values are in the column: \"diagnosis\"\n",
    "Output directory: \"/path/to/ouput_directory\"\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification inference Predict diabetes tuned model 3\n",
    "ict_prompt_2 = \"\"\"\n",
    "Use the classification model: /path/to/predict_diabetes/models/tuned_model_3/tuned_model_3.pkl \n",
    "Make predictions using the predictors in the file: /path/to/predict_diabetes/test_set.csv \n",
    "The ground truth values are in the column: \"Outcome\"\n",
    "Output directory: \"/path/to/ouput_directory\"\n",
    "Deploy the proper agent for this task.\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification inference Predict diabetes blended model\n",
    "ict_prompt_3 = \"\"\"\n",
    "Use the classification model: /path/to/predict_diabetes/models/blended_model/blended_model.pkl\n",
    "Make predictions using the predictors in the file: /path/to/predict_diabetes/test_set.csv \n",
    "The ground truth values are in the column: \"Outcome\"\n",
    "Output directory: \"/path/to/ouput_directory\"\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification inference Predict heart disease tuned model 3\n",
    "ict_prompt_4 = \"\"\"\n",
    "Use the classification model: /path/to/heart_disease/models/tuned_model_3/tuned_model_3.pkl\n",
    "Make predictions using the features in the file: /path/to/heart_disease/independent_eval_cohort.csv\n",
    "The ground truth values are in the column: \"target\"\n",
    "Output directory: \"/path/to/ouput_directory\"\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification inference Predict heart failure tuned model 2\n",
    "ict_prompt_5 = \"\"\"\n",
    "Use the classification model: /path/to/heart_failure/models/tuned_model_2/tuned_model_2.pkl\n",
    "Make predictions using the predictors in the file: /path/to//heart_failure/independent_eval_cohort.csv\n",
    "The ground truth values are in the column: \"DEATH_EVENT\"\n",
    "Output directory: \"/path/to/ouput_directory\"\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(ict_prompt_5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training prompts Regression Model (Tabulated data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for regression model development Life expectancy dataset\n",
    "trt_prompt_1 = \"\"\"\n",
    "Train a regression model using the file: /path/to/Life-Expectancy-Data.csv \n",
    "Exclude \"lightgbm\".\n",
    "Target column: \"Life_expectancy\".\n",
    "Save the results here: \"/path/to/ouput_directory\"\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(trt_prompt_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference prompts Regression Model (Tabulated data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for regression inference Life expectancy (providing the gt for comparison)\n",
    "irt_prompt_1 = \"\"\"\n",
    "Use the regression model: /path/to/life_expectancy/models/tuned_model_1/tuned_model_1.pkl\n",
    "Make predictions using the predictors in the file: /path/to/life_expectancy/independent_eval_cohort.csv\n",
    "The ground truth values are in the column: \"Life_expectancy\"\n",
    "Output directory: /path/to/ouput_directory\n",
    "Deploy the proper agent and tool for this task\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for regression inference Life expectancy (without gt)\n",
    "irt_prompt_2 = \"\"\"\n",
    "Use the regression model: /path/to/life_expectancy/models/tuned_model_1/tuned_model_1.pkl\n",
    "Make predictions using the predictors in the file: /path/to/life_expectancy/no_gt_independent_eval_cohort.csv\n",
    "Output directory: /path/to/ouput_directory\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(irt_prompt_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Prompts - Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for classification resnet18 model development for pneumoniamnist_28 dataset\n",
    "ict_prompt_1 = \"\"\"\n",
    "Deploy the appropriate agent and tool to train a classification resnet18 model. \n",
    "The train dataset directory: \"/path/to/pneumoniamnist_28/dataset_pneumoniamnist_28/train\",  \n",
    "the validation dataset directory: \"/path/to/pneumoniamnist_28/dataset_pneumoniamnist_28/val\",\n",
    "the test dataset directory: \"/path/to/pneumoniamnist_28/dataset_pneumoniamnist_28/test\", \n",
    "Number of classes 2. \n",
    "Use a batch size of 64. Number of epochs: 60\n",
    "Output directory: \"/path/to/ouput_directory\" \n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification resnet34 model development for pathmnist_64 dataset \n",
    "ict_prompt_2 = \"\"\"\n",
    "Train a classification resnet34 model. \n",
    "The train, validation and test datasets: /path/to/pathmnist_64/dataset_pathmnist_64. \n",
    "Number of classes 9. \n",
    "Use a batch size of 32. Set patience to 10 and number of epochs to 50.\n",
    "Output directory: /path/to/ouput_directory \n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification resnet50 model development for breastmnist_128 dataset\n",
    "ict_prompt_3 = \"\"\"\n",
    "Train a classification resnet50 model. \n",
    "The train, val and test data are available here: \"/path/to/breastmnist_128/dataset_breastmnist_128/\".\n",
    "Number of classes 2. \n",
    "Train for 50 epochs. Do not use early stopping. \n",
    "Output folder: \"/path/to/ouput_directory\"\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for classification resnet101 model development for dermamnist_224 dataset\n",
    "ict_prompt_4 = \"\"\"\n",
    "Train a classification resnet101 model. \n",
    "The train, val and test data are available here: \"/path/to/dermamnist_224/dataset_dermamnist_224\".\n",
    "Number of classes 7. Train for 200 epochs. Set patience for early stopping to 10. \n",
    "Output folder: \"/path/to/ouput_directory\"\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for classification resnet152 model development for organamnist_28 dataset\n",
    "ict_prompt_5 = \"\"\"\n",
    "Train a classification resnet152 model. \n",
    "The train, val and test data are available here: \"/path/to/organamnist_28/dataset_organamnist_28/\".\n",
    "Number of classes 11. Set patience to 5.\n",
    "Output folder: \"/path/to/ouput_directory\"\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for classification vgg16 model development for octmnist_28 dataset\n",
    "ict_prompt_6 = \"\"\"\n",
    "Train a classification vgg16 model. \n",
    "The train, val and test data are available here: \"/path/to/octmnist_28/dataset_octmnist_28/\".\n",
    "Number of classes 4. Do not use pretrained weights.\n",
    "Output folder: \"/path/to/ouput_directory\"\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for classification InceptionV3 model development for bloodmnist_128 dataset\n",
    "ict_prompt_7 = \"\"\"\n",
    "Train a classification InceptionV3 model. \n",
    "The train, val and test data are available here: \"/path/to/bloodmnist_128/dataset_bloodmnist_128\".\n",
    "Number of classes 8. Use pretrained weights and a batch size of 64. Train for 150 epochs.\n",
    "Output folder: \"/path/to/ouput_directory\"\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(ict_prompt_5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference Prompts - Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for inference with resnet18 model - pneumoniamnist_28 dataset\n",
    "ici_prompt_1 = \"\"\"\n",
    "Use the resnet-18 model available here: \"/path/to/pneumoniamnist_28/output_master_agent/resnet18_ict_prompt_1/best_model.pt\", \n",
    "to classify the images in this folder: \"/path/to/pneumoniamnist_28/dataset_pneumoniamnist_28/test\".\n",
    "The number of classes is 2. \n",
    "The ground truth labels for the evaluation are availabe here:\"/path/to/pneumoniamnist_28/inference/gt_test_labels.csv\".\n",
    "Save the evaluation output in this directory: \"/path/to/ouput_directory\". \n",
    "Deploy the appropriate agent and tool for this task.\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for inference with resnet34 model - pathmnist_64 dataset\n",
    "ici_prompt_2 = \"\"\"\n",
    "Use the resnet34 model available here: \"/path/to/pathmnist_64/output_master_agent/resnet34_ict_prompt_2/best_model.pt\", \n",
    "to classify the images in this folder: \"/path/to/pathmnist_64/dataset_pathmnist_64/test\".\n",
    "The number of classes is 9. \n",
    "The ground truth labels for the evaluation are availabe here:\"/path/to/pathmnist_64/inference/gt_test_labels.csv\".\n",
    "Save the evaluation output in this directory: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for inference with resnet50 model - breastmnist_128 dataset\n",
    "ici_prompt_3 = \"\"\"\n",
    "Use the resnet50 model available here: \"/path/to/breastmnist_128/output_master_agent/resnet50_ict_prompt_3/best_model.pt\",\n",
    "to classify the images in this folder: \"/path/to/breastmnist_128/dataset_breastmnist_128/test\".\n",
    "The number of classes is 2. \n",
    "The ground truth labels for the evaluation are availabe here: \"/path/to/breastmnist_128/inference/gt_test_labels.csv\".\n",
    "Output directory: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for inference with resnet101 model - dermamnist_224 dataset\n",
    "ici_prompt_4 = \"\"\"\n",
    "Use the resnet101 model available here: \"/path/to/dermamnist_224/output_master_agent/resnet101_ict_prompt_4/best_model.pt\",\n",
    "to classify the images in this folder: \"/path/to/dermamnist_224/dataset_dermamnist_224/test\".\n",
    "Number of classes 7. \n",
    "Output folder: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for inference with resnet152 model - organamnist_28 dataset\n",
    "ici_prompt_5 = \"\"\"\n",
    "Use the resnet152 model available here: \"/path/to/dermamnist_224/output_master_agent/resnet101_ict_prompt_4/best_model.pt\",\n",
    "to classify the images in this folder: \"/path/to/dermamnist_224/inference_test/images\".\n",
    "Number of classes 11. \n",
    "Output folder: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for inference with vgg16 model - octmnist_28 dataset\n",
    "ici_prompt_6 = \"\"\"\n",
    "Use the vgg16 model available here: \"/path/to/octmnist_28/output_master_agent/vgg16_ict_prompt_6/best_model.pt\",\n",
    "to classify the images in this folder: \"/path/to/octmnist_28/dataset_octmnist_28/test\".\n",
    "Number of classes 4. The ground truth labels are availabe in this directory: \"/path/to/octmnist_28/inference\".\n",
    "Output folder: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for inference with InceptionV3 model - bloodmnist_128 dataset\n",
    "ici_prompt_7 = \"\"\"\n",
    "Use the InceptionV3 model available here: \"/path/to/bloodmnist_128/output_master_agent/InceptionV3_ict_prompt_7/best_model.pt\",\n",
    "to classify the images in this folder: \"/path/to/bloodmnist_128/dataset_bloodmnist_128/test\".\n",
    "Number of classes 8. The ground truth labels are availabe in this directory: \"/path/to/bloodmnist_128/inference/gt_test_labels.csv\".\n",
    "Output folder: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(ici_prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_task_prompt_1 = \"\"\"\n",
    "Use TotalSegmentator with the total task to segment only the spleen from the CT scans (one at a time) available here: \"/path/to/test_multi_tasking/multi_task_prompt_1/ct_scans\". \n",
    "Save the mask files to \"/path/to/test_multi_tasking/multi_task_prompt_1/masks\".\n",
    "Rename each mask file to have the exact same filename with the corresponding CT scan.\n",
    "Use the CT scans and the corresponding spleen masks to extract radiomic features. \n",
    "Save the resulting radiomic features CSV file in here: \"/path/to/ouput_directory\".\n",
    "Use the saved csv file with the radiomic features to perform Exploratory Data Analysis, without producing plots, on the extracted features and save all EDA results in this directory: \"/path/to/ouput_directory\".\n",
    "Deploy the appropriate agent for each task.\n",
    "\"\"\"\n",
    "\n",
    "multi_task_prompt_2 = \"\"\"\n",
    "Using the nnUNet dataset 135, 3d full res fold_all model, segment the mpMRI scans in: \"/path/to/test_multi_tasking/multi_task_prompt_2/mpMRI_scans\". \n",
    "Save the mask files to: \"/path/to/test_multi_tasking/multi_task_prompt_2/masks\"\n",
    "Use the MRI scans and the corresponding masks to extract radiomic features for each label in the mask files. Use the followng filters: Exponential, Original, Wavelet.\n",
    "Extract radiomic features only from the T1 MRI scans. For example, the mask name for the first case will be 'BraTS2021_00000.nii.gz', the corresponding T1 image name will be 'BraTS2021_00000_0000.nii.gz'.\n",
    "Save the resulting radiomic features CSV files in this folder: \"/path/to/ouput_directory\".\n",
    "Use the saved csv files with the radiomic features to perform Exploratory Data Analysis. Save EDA results for each label in subfolders, in this directory:\"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "multi_task_prompt_3 = \"\"\"\n",
    "Perform a feature importance analysis for the file: \"/path/to/test_multi_tasking/multi_task_prompt_3/mamamia_features/dataset_mamamia.csv\".\n",
    "Save three csv files with the top 20, 50 and 100 features here: \"/path/to/ouput_directory\".\n",
    "Targert column is \"pcr\".\n",
    "Then use the csv file with the top 20 features to train a classifier. Save the output of the training process in this directory: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "multi_task_prompt_4 = \"\"\"\n",
    "Perform exploratory data analysis for the file: \"/path/to/breast_cancer_wisconsin_diagnosis_dataset.csv\".\n",
    "Save eda results and a csv files with the top 10 features here: \"/path/to/ouput_directory\".\n",
    "Targert column is \"diagnosis\".\n",
    "Then use the csv file with the top 10 features to train a classifier. Save the output of the training process in this directory: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "multi_task_prompt_5 = \"\"\"\n",
    "Train an InceptionV3 classification model using data available in the following directory: \"/path/to/pneumoniamnist_128/dataset_pneumoniamnist_128\".\n",
    "The number of classes is 2. Train for 100 epochs. Set patience to 10.\n",
    "Then, use the trained model to classify images in this directory: \"/path/to/pneumoniamnist_128/inference/test_data\".\n",
    "The ground truth labels for the evaluation are availabe here: \"/path/to/pneumoniamnist_128/inference/gt_test_labels.csv\".\n",
    "Save the trained model and inference results in this directory: \"/path/to/ouput_directory\".\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(multi_task_prompt_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Interactive communication with the master agent run the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradioUI(master_agent).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic_segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
