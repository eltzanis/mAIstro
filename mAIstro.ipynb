{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import logging\n",
    "from smolagents import Tool, CodeAgent, LiteLLMModel, GradioUI, HfApiModel\n",
    "from mAIstro_tools import (\n",
    "    PyRadiomicsFeatureExtractionTool,\n",
    "    EDAToolException,\n",
    "    ExploratoryDataAnalysisTool,\n",
    "    FeatureImportanceAnalysisTool,\n",
    "    NNUNetTrainingTool,\n",
    "    NNUNetInferenceTool,\n",
    "    TotalSegmentatorTool,\n",
    "    PyCaretClassificationTool,\n",
    "    PyCaretInferenceTool,\n",
    "    PyCaretRegressionInferenceTool,\n",
    "    PyCaretRegressionTool,\n",
    "    MedicalImageDataset,\n",
    "    PyTorchResNetTrainingTool,\n",
    "    PyTorchResNetInferenceTool,\n",
    "    PyTorchVGG16InferenceTool,\n",
    "    PyTorchVGG16TrainingTool,\n",
    "    PyTorchInceptionV3InferenceTool,\n",
    "    PyTorchInceptionV3TrainingTool\n",
    ")\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyradiomics_feature_extraction_tool = PyRadiomicsFeatureExtractionTool()\n",
    "eda_tool = ExploratoryDataAnalysisTool()\n",
    "feature_selection_tool = FeatureImportanceAnalysisTool()\n",
    "nnunet_training_tool = NNUNetTrainingTool()\n",
    "nnunet_inference_tool = NNUNetInferenceTool()\n",
    "totalsegmentator_tool = TotalSegmentatorTool()\n",
    "pycaret_class_inference_tool = PyCaretInferenceTool()\n",
    "pycaret_class_training_tool = PyCaretClassificationTool()\n",
    "pycaret_regression_training_tool = PyCaretRegressionTool()\n",
    "pycaret_regression_inference_tool = PyCaretRegressionInferenceTool()\n",
    "pytorch_resnet_inference_tool = PyTorchResNetInferenceTool()\n",
    "pytorch_resnet_training_tool = PyTorchResNetTrainingTool()\n",
    "pytorch_vgg16_inference_tool = PyTorchVGG16InferenceTool()\n",
    "pytorch_vgg16_training_tool = PyTorchVGG16TrainingTool()\n",
    "pytorch_inceptionv3_inference_tool = PyTorchInceptionV3InferenceTool()\n",
    "pytorch_inceptionv3_training_tool = PyTorchInceptionV3TrainingTool()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LLM Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use models through API calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gpt-4.1\n",
    "model = LiteLLMModel(model_id=\"openai/gpt-4.1\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#gpt-4o\n",
    "#model = LiteLLMModel(model_id=\"openai/gpt-4o\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#claude\n",
    "#model = LiteLLMModel(model_id=\"anthropic/claude-3-7-sonnet-20250219\", api_key=\"YOUR_API_KEY_HERE\") \n",
    "#deepseek V3\n",
    "#model = LiteLLMModel(model_id=\"deepseek/deepseek-chat\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#deepseek R1\n",
    "#model = LiteLLMModel(model_id=\"deepseek/deepseek-reasoner\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "#hf API\n",
    "#Qwen\n",
    "#model_id = \"Qwen/QwQ-32B\" \n",
    "#model = HfApiModel(model_id=model_id, token=\"YOUR_API_KEY_HERE\")\n",
    "#Llama 3.3\n",
    "#model_id = \"meta-llama/Llama-3.3-70B-Instruct\" \n",
    "#model = HfApiModel(model_id=model_id, token=\"YOUR_API_KEY_HERE\")\n",
    "\n",
    "#Together AI API\n",
    "#llama-4-Scout\n",
    "#model = LiteLLMModel(model_id=\"together_ai/meta-llama/Llama-4-Scout-17B-16E-Instruct\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#QwQ-32B\n",
    "#model = LiteLLMModel(model_id=\"together_ai/Qwen/QwQ-32B\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#Llama 3.3\n",
    "#model = LiteLLMModel(model_id=\"together_ai/meta-llama/Llama-3.3-70B-Instruct-Turbo-Free\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#Llama 3.1 8b\n",
    "#model = LiteLLMModel(model_id=\"together_ai/meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo-classifier\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#Mistral 24b\n",
    "#model = LiteLLMModel(model_id=\"together_ai/mistralai/Mistral-Small-24B-Instruct-2501\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#Mistral 7b\n",
    "#model = LiteLLMModel(model_id=\"together_ai/mistralai/Mistral-7B-Instruct-v0.2\", api_key=\"YOUR_API_KEY_HERE\")\n",
    "#DeepSeek R1 Distill Qwen 14B\n",
    "#model = LiteLLMModel(model_id=\"together_ai/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B\", api_key=\"YOUR_API_KEY_HERE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agents Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Radiomic extraction Agent\n",
    "radiomic_extraction_agent = CodeAgent(\n",
    "    tools = [pyradiomics_feature_extraction_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['os', 'pandas'],\n",
    "    name=\"radiomic_extraction_agent\",\n",
    "    description=\"Extracts radiomic features from medical images and saves them as CSV files\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#EDA Agent\n",
    "eda_agent = CodeAgent(\n",
    "    tools = [eda_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['os', 'pandas'],\n",
    "    name=\"eda_agent\",\n",
    "    description=\"Performs comprehensive exploratory data analysis\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#Feature Importance Agent\n",
    "feature_selection_agent = CodeAgent(\n",
    "    tools = [feature_selection_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['os', 'pandas'],\n",
    "    name=\"feature_importance_agent\",\n",
    "    description=\"Performs feature importance analysis and exports the most important features to CSV files\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#nnUNet Agent\n",
    "nnunet_agent = agent = CodeAgent(\n",
    "    tools = [nnunet_training_tool, nnunet_inference_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['re', 'subprocess', 'os'],\n",
    "    name=\"nnunet_agent\",\n",
    "    description=\"Uses the nnUNet framework for training and inference of medical image segmentation models\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#TotalSegmentator Agent\n",
    "totalsegmentator_agent = CodeAgent(\n",
    "    tools = [totalsegmentator_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['os'],\n",
    "    name=\"totalsegmentator_agent\",\n",
    "    description=\"Utilizes the TotalSegmentator framework to segment organs and tissues in medical imaging data\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#PyCaret classification Agent (tabulated data)\n",
    "pycaret_classification_agent = CodeAgent(\n",
    "    tools = [pycaret_class_training_tool, pycaret_class_inference_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['pycaret', 'setup', 'compare_models', 'tune_model', 'blend_models', \n",
    "                    'pull', 'predict_model', 'save_model',\n",
    "                    'plot_model', 'interpret_model', 'cuml', 'pandas'],\n",
    "    name=\"pycaret_classification_agent\",\n",
    "    description=\"Builds and deploys classification models using the PyCaret framework on tabular data inputs\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#PyCaret regression Agent (tabulated data)\n",
    "pycaret_regression_agent = CodeAgent(\n",
    "    tools = [pycaret_regression_training_tool, pycaret_regression_inference_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['pycaret', 'setup', 'compare_models', 'tune_model', 'blend_models', \n",
    "                    'pull', 'predict_model', 'save_model',\n",
    "                    'plot_model', 'interpret_model', 'cuml', 'pandas'],\n",
    "    name=\"pycaret_regression_agent\",\n",
    "    description=\"Builds and deploys regression models using the PyCaret framework on tabular data inputs\",\n",
    "    max_steps = 5\n",
    ")\n",
    "#Image classification Agent\n",
    "image_classification_agent = CodeAgent(\n",
    "    tools = [pytorch_resnet_training_tool, pytorch_resnet_inference_tool, \n",
    "             pytorch_inceptionv3_training_tool, pytorch_inceptionv3_inference_tool,\n",
    "             pytorch_vgg16_training_tool, pytorch_vgg16_inference_tool],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['os'],\n",
    "    name=\"image_classification_agent\",\n",
    "    description=\"Builds and deploys ResNet, Inceptionv3 and VGG16 image classification models\",\n",
    "    max_steps = 5\n",
    ")\n",
    "\n",
    "#Master Agent\n",
    "master_agent = CodeAgent(\n",
    "    tools = [],\n",
    "    managed_agents=[radiomic_extraction_agent, eda_agent, feature_selection_agent,\n",
    "                    nnunet_agent, totalsegmentator_agent, pycaret_classification_agent,\n",
    "                    pycaret_regression_agent, image_classification_agent],\n",
    "    model=model,\n",
    "    add_base_tools=True,\n",
    "    additional_authorized_imports=['os'],\n",
    "    name=\"master_agent\",\n",
    "    max_steps = 15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_agent.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radiomic Feature Extraction from CT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test: Generic query\n",
    "rfe_ct_prompt_1 = \"\"\"\n",
    "Perform a comprehensive radiomic feature extraction for the CT scans in: \"tests/test_radiomic_extractor_agent/ct/images\".\n",
    "The corresponding masks are here: \"tests/test_radiomic_extractor_agent/ct/labels\".\n",
    "Save the results here: \"tests/test_radiomic_extractor_agent/ct/results_generic_prompt\".\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(rfe_ct_prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test: Ask for specific radiomic freatures and filters.\n",
    "rfe_ct_prompt_2 = \"\"\"\n",
    "Extract shape and first order radiomic features for the CT scans in: \"tests/test_radiomic_extractor_agent/ct/images\".\n",
    "The respective masks are here: \"tests/test_radiomic_extractor_agent/ct/labels\".\n",
    "Save the results here: \"tests/test_radiomic_extractor_agent/ct/results_specific_features_and_filters\". \n",
    "Use the followng filters: Exponential, Gradient, LBP2D.'\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(rfe_ct_prompt_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radiomic Feature Extraction from MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test: Generic query for pre contrast MRI images (MAMAMIA dataset)\n",
    "rfe_mri_prompt_1 = \"\"\"\n",
    "Perform a comprehensive radiomic feature extraction for the MR scans in: \"tests/test_radiomic_extractor_agent/mri/mama_mia/images_pre_contrast\".\n",
    "The respective masks are here: \"tests/test_radiomic_extractor_agent/mri/mama_mia/labels\". \n",
    "Save the results here: \"tests/test_radiomic_extractor_agent/mri/mama_mia/results_pre_contrast\".\n",
    "\"\"\"\n",
    "master_agent.run(rfe_mri_prompt_1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test: Extraction of radiomic features from mpMRI images with multiple labels.\n",
    "#Asking specific features and filters\n",
    "\n",
    "rfe_mri_prompt_2 = \"\"\"\n",
    "Extract shape and glrlm and ngtdm radiomic features for the MR scans in: \"tests/test_radiomic_extractor_agent/mri/brats21/images_0\".\n",
    "The corresponding masks are here: \"tests/test_radiomic_extractor_agent/mri/brats21/labels\". \n",
    "Use the followng filters: Exponential, Gradient, SquareRoot.\n",
    "Save the results here: \"tests/test_radiomic_extractor_agent/mri/brats21/results_extra_filters/results_0\".'\n",
    "\"\"\"\n",
    "master_agent.run(rfe_mri_prompt_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for breast wisconsin dataset\n",
    "eda_prompt_1 = \"\"\"\n",
    "Perform comprehensive exploratory data analysis for the file: \"data/tabulated_datasets/classification/breast_cancer_wisconsin_diagnosis_dataset.csv\". \n",
    "Save the output here: \"tests/test_eda_agent/breast_wisconsin_eda_results\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for predict_diabetes dataset\n",
    "eda_prompt_2 =\"\"\"\n",
    "Perform comprehensive EDA for the file: \"data/tabulated_datasets/classification/predict_diabetes.csv. \n",
    "Save the output here: \"tests/test_eda_agent/predict_diabetes_eda_results\".\n",
    "\"\"\"\n",
    "#Prompt for heart disease dataset\n",
    "eda_prompt_3 = \"\"\"\n",
    "Perform comprehensive EDA for the file: data/tabulated_datasets/classification/heart_disease_classification.csv.\n",
    "Save the output here: \"tests/test_eda_agent/heart_disease_eda_results\".\n",
    "\"\"\"\n",
    "#Prompt for heart failure dataset\n",
    "eda_prompt_4 = \"\"\"\n",
    "Perform comprehensive EDA for the file: data/tabulated_datasets/classification/heart_failure_clinical_records_dataset.csv. \n",
    "Save the output here: \"tests/test_eda_agent/heart_failure_eda_results\".\n",
    "\"\"\"\n",
    "#Prompt for life expectancy dataset\n",
    "eda_prompt_5 = \"\"\"\n",
    "Perform comprehensive EDA for the file: data/tabulated_datasets/regression/Life-Expectancy-Data-Updated.csv. \n",
    "Save the output here: \"tests/test_eda_agent/life_expectancy_eda_results\".\n",
    "\"\"\"\n",
    "master_agent.run(eda_prompt_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Importance Analysis and Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for breast wisconsin dataset\n",
    "fia_prompt_1 = \"\"\"\n",
    "Perform feature importance analysis for the file: \"data/tabulated_datasets/classification/breast_cancer_wisconsin_diagnosis_dataset.csv\".\n",
    "Save three csv files with the top 5, 10 and 20 features here: \"tests/test_feature_selection_agent/results_breast_wisconsin_new\".\n",
    "Targert column is \"diagnosis\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for predict_diabetes dataset !Asking to export more features than the original file has.\n",
    "fia_prompt_2 = \"\"\"\n",
    "Perform feature importance analysis for the file: \"data/tabulated_datasets/classification/predict_diabetes.csv\".\n",
    "Save three csv files with the top 5, 10 and 20 features here: tests/test_feature_selection_agent/results_predict_diabetes.\n",
    "Targert column is \"Outcome\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for heart disease dataset\n",
    "fia_prompt_3 = \"\"\"\n",
    "Perform feature importance analysis for the file: \"data/tabulated_datasets/classification/heart_disease_classification.csv\".\n",
    "Save three csv files with the top 5, 10 features here: tests/test_feature_selection_agent/results_heart_disease.\n",
    "Targert column is \"target\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for heart failure dataset\n",
    "fia_prompt_4 = \"\"\"\n",
    "Perform feature importance analysis for the file: \"data/tabulated_datasets/classification/heart_failure_clinical_records_dataset.csv\".\n",
    "Save three csv files with the top 8 features here: \"tests/test_feature_selection_agent/results_heart_failure\".\n",
    "Targert column is \"DEATH_EVENT\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for life expectancy dataset\n",
    "fia_prompt_5 = \"\"\"\n",
    "Perform feature importance analysis for the file: data/tabulated_datasets/regression/Life-Expectancy-Data-Updated.csv.\n",
    "Save two csv files with the top 10 and 15 features here: tests/test_feature_selection_agent/results_life_expectancy.\n",
    "Targert column is \"Life_expectancy\". Create plots.'\n",
    "\"\"\"\n",
    "master_agent.run(fia_prompt_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nnUNet framework - Train and Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for training\n",
    "nnunet_prompt_1 = \"\"\"\n",
    "Train a segmentation 3d full res for the dataset in: \"nnUNet_paths/nnUNet_raw/Dataset020\". For fold 1.\n",
    "\"\"\"\n",
    "#Prompt for inference mpMRI (Brats21 dataset)\n",
    "nnunet_prompt_2 =\"\"\"\n",
    "Using the nnUNet dataset 135, 3d full res fold_all model, segment the scans in: \"tests/test_agent_inference_nnunet/brats21_input\". \n",
    "Output folder: \"tests/test_agent_inference_nnunet/brats_21_output\".\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(nnunet_prompt_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TotalSegmentator Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt 1 segmenting only one organ (CT)\n",
    "totalsegmentator_prompt_1 = \"\"\"\n",
    "Use TotalSegmentator with the total task to segment only the spleen from the CT scan at \"tests/test_totalsegmentator/ct_input/1_0000.nii.gz\". \n",
    "Save the mask to \"tests/test_totalsegmentator/ct_output/spleen\". \n",
    "\"\"\"\n",
    "\n",
    "#Prompt 2 segmenting three organs (CT)\n",
    "totalsegmentator_prompt_2 = \"\"\"\n",
    "Use TotalSegmentator with the total task to segment only the liver, stomach and right kidney from the CT scan at \"tests/test_totalsegmentator/ct_input/1_0000.nii.gz\" \n",
    "Save the mask to \"tests/test_totalsegmentator/ct_output/multiple_organs\" \n",
    "\"\"\"\n",
    "\n",
    "#Prompt 3 segmenting all available organs (CT)\n",
    "totalsegmentator_prompt_3 = \"\"\"\n",
    "Use TotalSegmentator with the total task to segment all available organs from the CT scan at tests/test_totalsegmentator/ct_input/1_0000.nii.gz. \n",
    "Save the mask to \"tests/test_totalsegmentator/ct_output/all_organs\" \n",
    "\"\"\"\n",
    "\n",
    "#Prompt 4 segmenting all available organs (MR)\n",
    "totalsegmentator_prompt_4 = \"\"\"\n",
    "Use TotalSegmentator with the total_mr task to segment all available organs from the MRI scan at \"tests/test_totalsegmentator/mri_input/mri.nii.gz\" \n",
    "Save the mask to \"tests/test_totalsegmentator/mri_output/mri_all_organs\". Do not use preview.\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(totalsegmentator_prompt_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training prompts Classification Model (Tabulated data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for classification model development Breast wisconsin\n",
    "tct_prompt_1 = \"\"\"\n",
    "Train a classification model using the tabulated data: \"data/tabulated_datasets/classification/breast_cancer_wisconsin_diagnosis_dataset.csv\".\n",
    "Target column: \"diagnosis\". Exclude lightgbm classifier. Set normalization and transormation to False.\n",
    "Save the results here: \"tests/test_classification_agent/breast_cancer_wisconsin\".\n",
    "Deploy the proper agent for this task.\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification model development Predict diabetes\n",
    "tct_prompt_2 = \"\"\"\n",
    "Train a classification model using the file: \"data/tabulated_datasets/classification/predict_diabetes.csv\". \n",
    "Target column: \"Outcome\". Exclude lightgbm classifier.\n",
    "Save the results here: \"tests/test_classification_agent/predict_diabetes\"\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification model development Predict Heart Disease\n",
    "tct_prompt_3 = \"\"\"\n",
    "Train a classification model using the file: data/tabulated_datasets/classification/heart_disease_classification.csv\n",
    "Target column: \"target\". Exclude lightgbm classifier.\n",
    "Save the results here: tests/test_classification_agent/heart_disease\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification model development Predict Heart Failure\n",
    "tct_prompt_4 = \"\"\"\n",
    "Train a classification model using the file: data/tabulated_datasets/classification/heart_failure_clinical_records_dataset.csv\n",
    "Target column: \"DEATH_EVENT\". Exclude lightgbm, dummy and catboost classifier.\n",
    "Save the results here: tests/test_classification_agent/heart_failure\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(tct_prompt_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference prompts Classification Model (Tabulated data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for classification inference Breast wisconsin tuned model 1\n",
    "ict_prompt_1 = \"\"\"\n",
    "Use the classification model: tests/test_classification_agent/breast_cancer_wisconsin/models/tuned_model_1/tuned_model_1.pkl \n",
    "Make predictions using the predictors in the file: data/tabulated_datasets/inference_test_data/breast_cancer_wisconsin_inference.csv \n",
    "The ground truth values are in the column: \"diagnosis\"\n",
    "Output directory: tests/test_classification_agent/Inference_results/breast_cancer_model_1\n",
    "Deploy the proper agent for this task.\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification inference Predict diabetes tuned model 3\n",
    "ict_prompt_2 = \"\"\"\n",
    "Use the classification model: tests/test_classification_agent/predict_diabetes/models/tuned_model_3/tuned_model_3.pkl \n",
    "Make predictions using the predictors in the file: data/tabulated_datasets/inference_test_data/predict_diabetes_inference.csv \n",
    "The ground truth values are in the column: \"Outcome\"\n",
    "Output directory: tests/test_classification_agent/Inference_results/predict_diabetes_model_3\n",
    "Deploy the proper agent for this task.\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification inference Predict diabetes blended model\n",
    "ict_prompt_3 = \"\"\"\n",
    "Use the classification model: tests/test_classification_agent/predict_diabetes/models/blended_model/blended_model.pkl\n",
    "Make predictions using the predictors in the file: data/tabulated_datasets/inference_test_data/predict_diabetes_inference.csv\n",
    "The ground truth values are in the column: \"Outcome\"\n",
    "Output directory: tests/test_classification_agent/Inference_results/predict_diabetes_blended_model\n",
    "Deploy the proper agent for this task.\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification inference Predict heart disease tuned model 3\n",
    "ict_prompt_4 = \"\"\"\n",
    "Use the classification model: tests/test_classification_agent/heart_disease/models/tuned_model_3/tuned_model_3.pkl\n",
    "Make predictions using the predictors in the file: data/tabulated_datasets/inference_test_data/heart_disease_inference.csv\n",
    "The ground truth values are in the column: \"target\"\n",
    "Output directory: tests/test_classification_agent/Inference_results/heart_disease\n",
    "Deploy the proper agent for this task.\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification inference Predict heart failure tuned model 2\n",
    "ict_prompt_5 = \"\"\"\n",
    "Use the classification model: tests/test_classification_agent/heart_failure/models/tuned_model_2/tuned_model_2.pkl\n",
    "Make predictions using the predictors in the file: data/tabulated_datasets/inference_test_data/heart_failure_inference.csv\n",
    "The ground truth values are in the column: \"DEATH_EVENT\"\n",
    "Output directory: tests/test_classification_agent/Inference_results/heart_failure\n",
    "Deploy the proper agent for this task.\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(ict_prompt_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training prompts Regression Model (Tabulated data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for regression model development Life expectancy dataset\n",
    "trt_prompt_1 = \"\"\"\n",
    "Train a regression model using the file: data/tabulated_datasets/regression/Life-Expectancy-Data-Updated.csv. \n",
    "Exclude \"lightgbm\".\n",
    "Target column: \"Life_expectancy\".\n",
    "Save the results here: tests/test_regression_agent/life_expectancy\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(trt_prompt_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference prompts Regression Model (Tabulated data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for regression inference Life expectancy (providing the gt for comparison)\n",
    "irt_prompt_1 = \"\"\"\n",
    "Use the regression model: tests/test_regression_agent/life_expectancy/models/tuned_model_1/tuned_model_1.pkl\n",
    "Make predictions using the predictors in the file: data/tabulated_datasets/inference_test_data/life_expectancy_inference_with_gt.csv\n",
    "The ground truth values are in the column: \"Life_expectancy\"\n",
    "Output directory: tests/test_regression_agent/inference_results/results_prompt_1\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for regression inference Life expectancy (without gt)\n",
    "irt_prompt_2 = \"\"\"\n",
    "Use the regression model: tests/test_regression_agent/life_expectancy/models/tuned_model_1/tuned_model_1.pkl \n",
    "Make predictions using the predictors in the file: data/tabulated_datasets/inference_test_data/life_expectancy_inference_no_gt.csv\n",
    "Output directory: tests/test_regression_agent/inference_results/results_prompt_2\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(irt_prompt_2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Prompts - Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for classification resnet18 model development for pneumoniamnist_28 dataset\n",
    "ict_prompt_1 = \"\"\"\n",
    "Deploy the appropriate agent and tool to train a classification resnet18 model. \n",
    "The train dataset directory: \"data/image_datasets/dataset_pneumoniamnist_28/train\",  \n",
    "the validation dataset directory: \"data/image_datasets/dataset_pneumoniamnist_28/val\",\n",
    "the test dataset directory: \"data/image_datasets/dataset_pneumoniamnist_28/test\", \n",
    "Number of classes 2. \n",
    "Use a batch size of 64. Number of epochs: 60\n",
    "Output directory: \"tests/test_image_classification_agent/pneumoniamnist_28/output/resnet18_ict_prompt_1\" \n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification resnet34 model development for pathmnist_64 dataset \n",
    "ict_prompt_2 = \"\"\"\n",
    "Train a classification resnet34 model. \n",
    "The train, validation and test datasets: \"data/image_datasets/dataset_pathmnist_64\". \n",
    "Number of classes 9. \n",
    "Use a batch size of 32. Set patience to 10 and number of epochs to 50.\n",
    "Output directory: tests/test_image_classification_agent/pathmnist_64/output/resnet34_ict_prompt_2 \n",
    "\"\"\"\n",
    "\n",
    "#Prompt for classification resnet50 model development for breastmnist_128 dataset\n",
    "ict_prompt_3 = \"\"\"\n",
    "Train a classification resnet50 model. \n",
    "The train, val and test data are available here: \"data/image_datasets/dataset_breastmnist_128/\".\n",
    "Number of classes 2. \n",
    "Train for 50 epochs. Do not use early stopping. \n",
    "Output folder: \"tests/test_image_classification_agent/breastmnist_128/output/resnet50_ict_prompt_3\"\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for classification resnet101 model development for dermamnist_224 dataset\n",
    "ict_prompt_4 = \"\"\"\n",
    "Train a classification resnet101 model. \n",
    "The train, val and test data are available here: \"data/image_datasets/dataset_dermamnist_224\".\n",
    "Number of classes 7. Train for 200 epochs. Set patience for early stopping to 10. \n",
    "Output folder: \"tests/test_image_classification_agent/dermamnist_224/output/resnet101_ict_prompt_4\"\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for classification resnet152 model development for organamnist_28 dataset\n",
    "ict_prompt_5 = \"\"\"\n",
    "Train a classification resnet152 model. \n",
    "The train, val and test data are available here: \"data/image_datasets/dataset_organamnist_28/\".\n",
    "Number of classes 11. Set patience to 5.\n",
    "Output folder: \"tests/test_image_classification_agent/organamnist_28/output/resnet152_ict_prompt_5\"\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for classification vgg16 model development for octmnist_28 dataset\n",
    "ict_prompt_6 = \"\"\"\n",
    "Train a classification vgg16 model. \n",
    "The train, val and test data are available here: \"data/image_datasets/dataset_octmnist_28/\".\n",
    "Number of classes 4. Do not use pretrained weights.\n",
    "Output folder: \"tests/test_image_classification_agent/octmnist_28/output/vgg16_ict_prompt_6\"\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for classification InceptionV3 model development for bloodmnist_128 dataset\n",
    "ict_prompt_7 = \"\"\"\n",
    "Train a classification InceptionV3 model. \n",
    "The train, val and test data are available here: \"data/image_datasets/dataset_bloodmnist_128\".\n",
    "Number of classes 8. Use pretrained weights and a batch size of 64. Train for 150 epochs.\n",
    "Output folder: \"tests/test_image_classification_agent/bloodmnist_128/output/InceptionV3_ict_prompt_7\"\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(ict_prompt_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference Prompts - Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prompt for inference with resnet18 model - pneumoniamnist_28 dataset\n",
    "ici_prompt_1 = \"\"\"\n",
    "Use the resnet-18 model available here: \"tests/test_image_classification_agent/pneumoniamnist_28/output/resnet18_ict_prompt_1/best_model.pt\", \n",
    "to classify the images in this folder: \"data/image_datasets_inference/pneumoniamnist_28_inference/test_images\".\n",
    "The number of classes is 2. \n",
    "The ground truth labels for the evaluation are availabe here:\"data/image_datasets_inference/pneumoniamnist_28_inference/gt_test_labels.csv\".\n",
    "Save the evaluation output in this directory: \"tests/test_image_classification_agent/pneumoniamnist_28/inference_results\". \n",
    "Deploy the appropriate agent and tool for this task.\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for inference with resnet34 model - pathmnist_64 dataset\n",
    "ici_prompt_2 = \"\"\"\n",
    "Use the resnet34 model available here: \"tests/test_image_classification_agent/pathmnist_64/output/resnet34_ict_prompt_2/best_model.pt\", \n",
    "to classify the images in this folder: \"data/image_datasets_inference/pathmnist_64_inference/test_images\".\n",
    "The number of classes is 9. \n",
    "The ground truth labels for the evaluation are availabe here:\"data/image_datasets_inference/pathmnist_64_inference/gt_test_labels.csv\".\n",
    "Save the evaluation output in this directory: \"tests/test_image_classification_agent/pathmnist_64/inference_results\".\n",
    "\"\"\"\n",
    "\n",
    "#Prompt for inference with resnet50 model - breastmnist_128 dataset\n",
    "ici_prompt_3 = \"\"\"\n",
    "Use the resnet50 model available here: \"tests/test_image_classification_agent/breastmnist_128/output/resnet50_ict_prompt_3/best_model.pt\",\n",
    "to classify the images in this folder: \"data/image_datasets_inference/breastmnist_128_inference/test_images\".\n",
    "The number of classes is 2. \n",
    "The ground truth labels for the evaluation are availabe here: \"data/image_datasets_inference/breastmnist_128_inference/gt_test_labels.csv\".\n",
    "Output directory: \"tests/test_image_classification_agent/breastmnist_128/inference_results\".\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for inference with resnet101 model - dermamnist_224 dataset\n",
    "ici_prompt_4 = \"\"\"\n",
    "Use the resnet101 model available here: \"tests/test_image_classification_agent/dermamnist_224/output/resnet101_ict_prompt_4/best_model.pt\",\n",
    "to classify the images in this folder: \"data/image_datasets_inference/dermamnist_224_inference/test_images\".\n",
    "Number of classes 7. \n",
    "Output folder: \"tests/test_image_classification_agent/dermamnist_224/inference_results\".\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for inference with resnet152 model - organamnist_28 dataset\n",
    "ici_prompt_5 = \"\"\"\n",
    "Use the resnet152 model available here: \"tests/test_image_classification_agent/organamnist_28/output/resnet152_ict_prompt_5\",\n",
    "to classify the images in this folder: \"data/image_datasets_inference/organamnist_28_inference/test_images\".\n",
    "Number of classes 11. \n",
    "Output folder: \"tests/test_image_classification_agent/organamnist_28/inference_results\".\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for inference with vgg16 model - octmnist_28 dataset\n",
    "ici_prompt_6 = \"\"\"\n",
    "Use the vgg16 model available here: \"tests/test_image_classification_agent/octmnist_28/output/vgg16_ict_prompt_6/best_model.pt\",\n",
    "to classify the images in this folder: \"data/image_datasets_inference/octmnist_28_inference/test_images\".\n",
    "Number of classes 4. \n",
    "The ground truth labels are availabe in this directory: \"data/image_datasets_inference/octmnist_28_inference/gt_test_labels.csv\".\n",
    "Output folder: \"tests/test_image_classification_agent/octmnist_28/inference_results\".\n",
    "\"\"\"\n",
    "\n",
    "##Prompt for inference with InceptionV3 model - bloodmnist_128 dataset\n",
    "ici_prompt_7 = \"\"\"\n",
    "Use the InceptionV3 model available here: \"tests/test_image_classification_agent/bloodmnist_128/output/InceptionV3_ict_prompt_7/best_model.pt\",\n",
    "to classify the images in this folder: \"data/image_datasets_inference/bloodmnist_128_inference/test_images\".\n",
    "Number of classes 8. \n",
    "The ground truth labels are availabe in this directory: \"data/image_datasets_inference/bloodmnist_128_inference/gt_test_labels.csv\".\n",
    "Output folder: \"tests/test_image_classification_agent/bloodmnist_128/inference_results\".\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(ici_prompt_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_task_prompt_1 = \"\"\"\n",
    "For each CT scan file located in the folder: \"tests/test_multi_tasking/multi_task_prompt_1/ct_scans\":\n",
    "    1) Use TotalSegmentator with the total task to segment only the spleen.\n",
    "    2) After segmentation, do not keep the default filename (e.g., spleen.nii.gz). Instead, rename the spleen mask so that its filename exactly matches the original CT scan filename (e.g., if the CT scan was 1.nii.gz, rename the mask to 1.nii.gz).\n",
    "    3) Save the renamed mask in the folder: \"tests/test_multi_tasking/multi_task_prompt_1/masks\".\n",
    "Repeat the steps above for every CT scan in the folder.\n",
    "Once all spleen masks are saved and correctly renamed:\n",
    "    4)Use each CT scan and its corresponding spleen mask to extract radiomic features.\n",
    "    5)Save the radiomic features into a single CSV file in: \"tests/test_multi_tasking/multi_task_prompt_1/radiomic_features\".\n",
    "    6)Perform Exploratory Data Analysis (EDA) on the extracted radiomic features, without generating plots.\n",
    "    7)Save all EDA results into: \"tests/test_multi_tasking/multi_task_prompt_1/eda_results\".\n",
    "\"\"\"\n",
    "multi_task_prompt_2 = \"\"\"\n",
    "Using the nnUNet dataset 135, 3d full res, fold_all model, segment the mpMRI scans located in: \"tests/test_multi_tasking/multi_task_prompt_2/mpMRI_scans\".\n",
    "Save the mask files to: \"tests/test_multi_tasking/multi_task_prompt_2/masks\".\n",
    "After segmentation:\n",
    "    1)For each predicted mask file (e.g., BraTS2021_00000.nii.gz), rename the mask file so that it matches the corresponding T1 image filename.\n",
    "    For example:\n",
    "    If the mask is BraTS2021_00000.nii.gz and the corresponding T1 scan is BraTS2021_00000_0000.nii.gz, then rename the mask file to BraTS2021_00000_0000.nii.gz (i.e., copy the T1 filename exactly).\n",
    "Once all mask files are correctly renamed:\n",
    "    2)Use the T1-weighted MRI scans available here: \"tests/test_multi_tasking/multi_task_prompt_2/T1_scans\" and their corresponding masks available here: \"tests/test_multi_tasking/multi_task_prompt_2/masks\"\n",
    "    to extract radiomic features for each label in the masks.\n",
    "    Use the following image filters: Exponential, Original, Wavelet.\n",
    "    3)Save each resulting radiomic features CSV file in: \"tests/test_multi_tasking/multi_task_prompt_2/radiomic_features\".\n",
    "    4)Perform Exploratory Data Analysis (EDA) for the extracted features separately for each label. Do not generate any plots.\n",
    "    Save the EDA results for each label in subfolders inside: \"tests/test_multi_tasking/multi_task_prompt_2/eda_results\".\n",
    "\"\"\"\n",
    "\n",
    "multi_task_prompt_3 = \"\"\"\n",
    "Perform a feature importance analysis for the file: \"tests/test_multi_tasking/multi_task_prompt_3/mamamia_features/dataset_mamamia.csv\".\n",
    "Save three csv files with the top 20, 50 and 100 features here: \"tests/test_multi_tasking/multi_task_prompt_3/mamamia_features/feature_importance_analysis_results\".\n",
    "Targert column is \"pcr\".\n",
    "Then use the csv file with the top 20 features to train a classifier. \n",
    "Save the output of the training process in this directory: \"tests/test_multi_tasking/multi_task_prompt_3/mamamia_features/classifier\".\n",
    "\"\"\"\n",
    "\n",
    "multi_task_prompt_4 = \"\"\"\n",
    "Perform exploratory data analysis for the file: \"data/tabulated_datasets/classification/breast_cancer_wisconsin_diagnosis_dataset.csv\".\n",
    "Save eda results and a csv files with the top 10 features here: \"tests/test_multi_tasking/multi_task_prompt_4\".\n",
    "Targert column is \"diagnosis\".\n",
    "Then use the csv file with the top 10 features to train a classifier. \n",
    "Save the output of the training process in this directory: \"tests/test_multi_tasking/multi_task_prompt_4/classifier\".\n",
    "\"\"\"\n",
    "\n",
    "multi_task_prompt_5 = \"\"\"\n",
    "Train an InceptionV3 classification model using data available in the following directory: \"data/image_datasets/dataset_pneumoniamnist_128\".\n",
    "The number of classes is 2. Train for 100 epochs. Set patience to 10.\n",
    "Then, use the trained model to classify images in this directory: \"data/image_datasets_inference/pneumoniamnist_128_inference/test_images\".\n",
    "The ground truth labels for the evaluation are availabe here: \"data/image_datasets_inference/pneumoniamnist_128_inference/gt_test_labels.csv\".\n",
    "Save the trained model and inference results in this directory: \"tests/test_multi_tasking/multi_task_prompt_5\".\n",
    "\"\"\"\n",
    "\n",
    "master_agent.run(multi_task_prompt_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GradioUI(master_agent).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
